import torch
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
import os

class ChatBot:
    def __init__(self, model_path="trained_model"):
        self.model_path = model_path
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.tokenizer = None
        self.model = None
        self.load_model()
        
    def load_model(self):
        if not os.path.exists(self.model_path):
            print(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà: {self.model_path}")
            return
        try:
            print(f"üì¶ ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏≤‡∏Å: {self.model_path}")
            self.tokenizer = AutoTokenizer.from_pretrained(self.model_path)
            self.model = AutoModelForSeq2SeqLM.from_pretrained(self.model_path)
            self.model.to(self.device)
            self.model.eval()
            print("‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô")
        except Exception as e:
            print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•: {e}")

    def generate_answer(self, input_text, max_length=128, num_beams=4, temperature=0.7):
        if not self.model or not self.tokenizer:
            return "‚ùå ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÇ‡∏´‡∏•‡∏î"
        if not input_text.strip():
            return "‚ö†Ô∏è ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏™‡πà‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°"

        try:
            input_ids = self.tokenizer.encode(
                input_text, return_tensors="pt", truncation=True, max_length=512
            ).to(self.device)
            with torch.no_grad():
                outputs = self.model.generate(
                    input_ids, max_length=max_length,
                    num_beams=num_beams, temperature=temperature,
                    do_sample=True, pad_token_id=self.tokenizer.pad_token_id,
                    eos_token_id=self.tokenizer.eos_token_id
                )
            decoded = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
            return decoded.strip()
        except Exception as e:
            return f"[Error]: {e}"

    def chat(self):
        print("ü§ñ ‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏ï‡πâ‡∏≠‡∏ô‡∏£‡∏±‡∏ö! ‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì")
        print("‡∏û‡∏¥‡∏°‡∏û‡πå 'exit' ‡∏´‡∏£‡∏∑‡∏≠ '‡∏≠‡∏≠‡∏Å' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏à‡∏ö")
        print("-" * 40)
        while True:
            try:
                query = input("üß† ‡∏Ñ‡∏∏‡∏ì: ").strip()
                if query.lower() in ["exit", "‡∏≠‡∏≠‡∏Å", "bye", "quit"]:
                    print("üëã ‡∏•‡∏≤‡∏Å‡πà‡∏≠‡∏ô")
                    break
                answer = self.generate_answer(query)
                print(f"ü§ñ ‡∏ö‡∏≠‡∏ó: {answer}")
                print("-" * 40)
            except KeyboardInterrupt:
                print("\nüëã ‡∏•‡∏≤‡∏Å‡πà‡∏≠‡∏ô")
                break

if __name__ == "__main__":
    bot = ChatBot()
    if bot.model:
        bot.chat()
